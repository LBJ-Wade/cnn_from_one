{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 ZeroNet\n",
    "\n",
    "まずはスタート地点として『ゼロから作るDeep Learning』の８章のＣＮＮを PyTorch で実装する。\n",
    "ZeroNet （勝手に命名）\n",
    "\n",
    "* 3 x 3 のフィルターを基本とした VGG-16 の簡略版\n",
    "* conv - conv - pool - conv - conv - pool - fully - dropout - fully - dropout - softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 1.1.0\n",
      "GPU available:  True\n",
      "GPU: Quadro K620\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # F.relu とか\n",
    "\n",
    "print('PyTorch version', torch.__version__)\n",
    "\n",
    "# GPU が動いていることを確認\n",
    "print('GPU available: ', torch.cuda.is_available())\n",
    "print('GPU:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ../input\n",
      "    Split: Train\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ../input\n",
      "    Split: Test\n"
     ]
    }
   ],
   "source": [
    "# torchvision を使って MNIST データをロード。初回はダウンロードする。\n",
    "# デフォルトではデータが PIL.Image なので Tensor に変換する\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "\n",
    "train = torchvision.datasets.MNIST(root='../input', train=True,\n",
    "                                   download=True, transform=to_tensor)\n",
    "test = torchvision.datasets.MNIST(root='../input', train=False,\n",
    "                                  transform=to_tensor)\n",
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datasets とは\n",
    "\n",
    "`__len__` と `__getitem__` を持っている。この二つがあれば、`DataLoader` で使えるらしい。\n",
    "\n",
    "```python\n",
    "class MyDataSet(VisionDataset):\n",
    "    def __len__():\n",
    "        pass\n",
    "    \n",
    "    def __getitem__():\n",
    "        pass\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "d = MyDataSet()\n",
    "len(d)      # データ総数\n",
    "X, y = d[i] # feature と label を返す\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "# 学習時に mini batch に切り分けてくれる\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = train[0]\n",
    "\n",
    "print('image shape', tuple(img.shape))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title(label)\n",
    "plt.imshow(img[0, :, :], cmap='Greys') # img[channel, x, y] なので channel = 0 を表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "\n",
    "ネットワークを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        # ここでは各レイヤーを定義しているだけ。繋がっていない\n",
    "        # Sequential を使って __init__ 時点でつなぐ流儀もある\n",
    "        super(ZeroNet, self).__init__()\n",
    "        self.conv1a = nn.Conv2d(1, 16, 3, padding=1)   # 28x28x1 -> 28x28x16\n",
    "        self.conv1b = nn.Conv2d(16, 16, 3, padding=1)  # 28x28x16 -> 28x28x16 \n",
    "        self.pool1 = nn.MaxPool2d(2, 2)                # 28x28x16 -> 14x14x16\n",
    "        self.conv2a = nn.Conv2d(16, 32, 3, padding=1)  # 14x14x16 -> 14x14x32\n",
    "        self.conv2b = nn.Conv2d(32, 32, 3, padding=2)  # 14x14x32 -> 15x15x32\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)                # 15x15x32 -> 8x8x32\n",
    "        self.conv3a = nn.Conv2d(32, 64, 3, padding=1)  # 8x8x32 -> 8x8x64\n",
    "        self.conv3b = nn.Conv2d(64, 64, 3, padding=1)  # 8x8x64 -> 8x8x64\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)                # 8x8x64 -> 4x4x64\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 50)           # fully connected 50\n",
    "        self.dropout1 = nn.Dropout2d()\n",
    "        self.fc2 = nn.Linear(50, 10)                   # 10 is the number of classes\n",
    "        self.dropout2 = nn.Dropout2d()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # レイヤーをつなげている\n",
    "        x = F.relu(self.conv1a(x))\n",
    "        x = F.relu(self.conv1b(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2a(x))\n",
    "        x = F.relu(self.conv2b(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.conv3a(x))\n",
    "        x = F.relu(self.conv3b(x))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = x.view(-1, 4 * 4 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "net = ZeroNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "最小限のコードは\n",
    "\n",
    "```python\n",
    "epochs = 10\n",
    "\n",
    "for iepoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader, 0): \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いろいろ測定と追加する\n",
    "\n",
    "* かかった時間\n",
    "* Loss と Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss 9.2688e-01 9.2007e-01, Test accuracy 5802/10000 58.0200 %\n",
      "Epoch 2: loss 9.1714e-01 9.1914e-01, Test accuracy 5846/10000 58.4600 %\n",
      "Epoch 3: loss 9.2093e-01 9.1034e-01, Test accuracy 5871/10000 58.7100 %\n",
      "Epoch 4: loss 9.1366e-01 9.2463e-01, Test accuracy 5838/10000 58.3800 %\n",
      "Epoch 5: loss 9.0110e-01 9.1915e-01, Test accuracy 5848/10000 58.4800 %\n",
      "Epoch 6: loss 9.0347e-01 9.3018e-01, Test accuracy 5819/10000 58.1900 %\n",
      "Epoch 7: loss 9.0220e-01 9.1368e-01, Test accuracy 5845/10000 58.4500 %\n",
      "Epoch 8: loss 8.9686e-01 9.1771e-01, Test accuracy 5897/10000 58.9700 %\n",
      "Epoch 9: loss 8.9382e-01 9.3365e-01, Test accuracy 5793/10000 57.9300 %\n",
      "Epoch 10: loss 8.9610e-01 9.0464e-01, Test accuracy 5882/10000 58.8200 %\n",
      "Epoch 11: loss 8.9328e-01 9.1197e-01, Test accuracy 5886/10000 58.8600 %\n",
      "Epoch 12: loss 8.8384e-01 9.1752e-01, Test accuracy 5800/10000 58.0000 %\n",
      "Epoch 13: loss 8.9571e-01 8.9531e-01, Test accuracy 5882/10000 58.8200 %\n",
      "Epoch 14: loss 8.8334e-01 9.2406e-01, Test accuracy 5783/10000 57.8300 %\n",
      "Epoch 18: loss 8.8395e-01 9.0308e-01, Test accuracy 5871/10000 58.7100 %\n",
      "Epoch 19: loss 8.7369e-01 9.3067e-01, Test accuracy 5837/10000 58.3700 %\n",
      "Epoch 20: loss 8.7475e-01 8.9846e-01, Test accuracy 5860/10000 58.6000 %\n",
      "Finished Training\n",
      "Training 31.45 ± 1.56 sec per epoch\n",
      "Test evaluation 2.0578 ± 0.0117 sec per epoch\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "scores_test = []\n",
    "times_train = []\n",
    "times_test = []\n",
    "\n",
    "for iepoch in range(epochs):\n",
    "    time_train = 0.0\n",
    "    loss_train = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader, 0): \n",
    "        ts = time.time_ns() / (10 ** 9)\n",
    "            \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        te = time.time_ns() / (10 ** 9)\n",
    "        time_train += (te - ts)\n",
    "\n",
    "        loss_train += loss.item()\n",
    "\n",
    "    # average loss during the epoch\n",
    "    loss_train /= len(train_loader)\n",
    "    losses_train.append(loss_train)\n",
    "    \n",
    "    times_train.append(time_train)\n",
    "    \n",
    "    # For each epoch\n",
    "    ts = time.time_ns() / (10 ** 9)\n",
    "        \n",
    "    loss_test = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(test_loader, 0):\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_test += loss\n",
    "                \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    te = time.time_ns() / (10 ** 9)\n",
    "    times_test.append(te - ts)\n",
    "    \n",
    "    loss_test /= len(test_loader)\n",
    "    losses_test.append(loss_test)\n",
    "    scores_test.append(100 * correct / total)\n",
    "    \n",
    "\n",
    "    print('Epoch %d: loss %.4e %.4e, Test accuracy %d/%d %.4f %%' %\n",
    "          (iepoch + 1, loss_train, loss_test,\n",
    "           correct, total, (100 * correct / total)))\n",
    "\n",
    "    \n",
    "print('Finished Training')\n",
    "print('Training %.2f ± %.2f sec per epoch' % (np.mean(times_train), np.std(times_train)))\n",
    "print('Test evaluation %.4f ± %.4f sec per epoch' % (np.mean(times_test), np.std(times_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.plot(losses_train, label='train')\n",
    "plt.plot(losses_test, label='test')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.plot(scores_test, label='train')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
