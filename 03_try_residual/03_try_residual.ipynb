{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_try_residual.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w4tl4CHYaDV",
        "colab_type": "text"
      },
      "source": [
        "# Try residual\n",
        "\n",
        "論文\n",
        "He et al., Deep Residual Learning for Image Recognition, https://arxiv.org/abs/1512.03385\n",
        "\n",
        "conv + ReLU + ... を素通りさせるルートを加えるのが **residual**.\n",
        "\n",
        "### 基本\n",
        "\n",
        "Tensor をいろいろやった [$ x \\mapsto F(x)$]  あとに元の $x$ を足す:\n",
        "$ x \\mapsto F(x) + x$.\n",
        "\n",
        "\n",
        "具体的にどこの x をいつ戻すかというと、先人の知恵によれば\n",
        "\n",
        "```\n",
        "x → conv → batch norm → ReLU → conv → batch norm → + → ReLU\n",
        "```\n",
        "\n",
        "x を保存しておいて、+ のところで足す. \n",
        "\n",
        "### 変形版\n",
        "\n",
        "x と F(x) は tensor の形が違うのでは？\n",
        "\n",
        "Same padding + channel 数不変の場合は良い。しかし: \n",
        "\n",
        "1.  valid padding だと大きさがちょっと減る\n",
        "2. channel数は同じのこともあれば、２倍くらいに増えることもよくある.\n",
        "3. stride > 2 だと大きさが大きく減る\n",
        "\n",
        "\n",
        "(1) についてはわからない。 $x$ の両端を切ればいいと思うけど、普通はpadding で大きさを同じにする.\n",
        "\n",
        "PyTorch 公式の ResNet を読むと\n",
        "https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L25\n",
        "\n",
        "convolution (ReLU なし) と batch normalization を入れてある.\n",
        "\n",
        "$$\n",
        "F(x) + \\mathrm{norm}(\\mathrm{conv}(x))\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "Conv は普通の学習されるパラメタを持っている。違いは ReLu の非線形性を持っていないこと.\n",
        "\n",
        "```python\n",
        " if (stride != 1) or (self.in_channels != out_channels):\n",
        "    downsample = nn.Sequential(\n",
        "      conv3x3(self.in_channels, out_channels, stride=stride),\n",
        "      nn.BatchNorm2d(out_channels))\n",
        " ```\n",
        "                \n",
        "(3) stride の対処法も同じ. F(x) でやっている stride と同じ stride で conv して ReLU 無し. F(x) 内では普通２回の conv をやるけど、stride > 2 をするのは初回だけで、２回目は形を変えない conv をしている.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8gIqSKRYVzj",
        "colab_type": "code",
        "outputId": "5cc4abf5-f408-4dab-81b6-b4a977ba6148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F  # F.relu とか\n",
        "\n",
        "print('PyTorch version', torch.__version__)\n",
        "\n",
        "\n",
        "# GPU が使えるなら使う\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:', device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print('GPU:', torch.cuda.get_device_name(0))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version 1.1.0\n",
            "Device: cuda:0\n",
            "GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZpaT67ZYbSh",
        "colab_type": "code",
        "outputId": "bc315bc0-04e6-4074-8372-0ca5ebb8854a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# データが PIL.Image なので、torch.Tensor に変換する\n",
        "to_tensor = torchvision.transforms.ToTensor()\n",
        "\n",
        "train = torchvision.datasets.MNIST(root='./input', train=True,\n",
        "                                   download=True, transform=to_tensor)\n",
        "test = torchvision.datasets.MNIST(root='./input', train=False,\n",
        "                                  transform=to_tensor)\n",
        "print(train)\n",
        "print(test)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./input/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:02, 4520147.93it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./input/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./input/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 68372.01it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./input/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./input/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:01, 1145982.32it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./input/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./input/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 26013.02it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./input/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./input\n",
            "    Split: Train\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./input\n",
            "    Split: Test\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhCUGdMkbpsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "test_loader  = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG0GvVLyejVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        # ここでは各レイヤーを定義しているだけ。繋がっていない\n",
        "        # Sequential を使って __init__ 時点でつなぐ流儀もある\n",
        "        super(ResidualNet, self).__init__()\n",
        "        self.conv1a = nn.Conv2d(1,  16, 3)             # 28x28x1  -> 26x26x16\n",
        "        self.norm1a = nn.BatchNorm2d(16)        \n",
        "        self.conv1b = nn.Conv2d(16, 16, 3, padding=1)  # 26x24x16 -> 26x26x16\n",
        "        self.norm1b = nn.BatchNorm2d(16)\n",
        "        self.conv1c = nn.Conv2d(16, 16, 3, padding=1)  # 26x26x16 -> 26x26x16\n",
        "        self.norm1c = nn.BatchNorm2d(16)\n",
        "        self.pool1  = nn.MaxPool2d(2, 2)               # 26x26x16 -> 13x13x16\n",
        "        \n",
        "        self.conv2a = nn.Conv2d(16, 32, 3)             # 13x13x16 -> 11x11x32\n",
        "        self.norm2a = nn.BatchNorm2d(32)\n",
        "        self.conv2r = nn.Conv2d(16, 32, 3)             # 迂回経路\n",
        "        self.norm2r = nn.BatchNorm2d(32)\n",
        "        \n",
        "        self.conv2b = nn.Conv2d(32, 32, 3, padding=1)  # 11x11x32 -> 11x11x32\n",
        "        self.norm2b = nn.BatchNorm2d(32)\n",
        "        self.conv2c = nn.Conv2d(32, 32, 3, padding=1)  # 11x11x32 -> 11x11x32\n",
        "        self.norm2c = nn.BatchNorm2d(32)\n",
        "        self.pool2  = nn.MaxPool2d(2, 2)               # 11x11x32 -> 5x5x32\n",
        "        \n",
        "        self.fc1    = nn.Linear(5 * 5 * 32, 50)  # fully connected -> 50\n",
        "        self.dropout1 = nn.Dropout2d()           # default dropout rate is 0.5\n",
        "        self.fc2      = nn.Linear(50, 10)        # 50 -> 10 number of classes\n",
        "        #self.dropout2 = nn.Dropout2d()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # レイヤーをつなげる\n",
        "        x = F.relu(self.norm1a(self.conv1a(x)))\n",
        "        \n",
        "        # residual block 1\n",
        "        residual = x   # x\n",
        "        \n",
        "        x = F.relu(self.norm1b(self.conv1b(x)))\n",
        "        x = self.norm1c(self.conv1c(x))\n",
        "        x += residual  # x + F(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.relu(self.pool1(x))\n",
        "        \n",
        "        # 変形 residual\n",
        "        out = F.relu(self.norm2a(self.conv2a(x)))  # 普通の conv + ReLU\n",
        "        residual = self.norm2r(self.conv2r(x))     # ReLU 無し linear mapping\n",
        "                                                   # 点線\n",
        "        x = out + residual\n",
        "        \n",
        "        # residual block 2\n",
        "        residual = x\n",
        "        x = F.relu(self.norm2b(self.conv2b(x)))\n",
        "        x = self.norm2c(self.conv2c(x))\n",
        "        x + residual\n",
        "        x = F.relu(self.pool2(x))\n",
        "        \n",
        "        x = x.view(-1, 5 * 5 * 32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        #x = self.dropout2(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2Ono7AU81sG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "71252e0d-02f5-48c2-f401-8ddc8a991904"
      },
      "source": [
        "# Model と 最適化方法\n",
        "model = ResidualNet()\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "model = model.to(device)  # send to GPU if available\n",
        "\n",
        "# 訓練の進行具合を記録\n",
        "def measure_scores(name, loader, history, *, nbatch=100):\n",
        "    loss_sum = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (images, labels) in enumerate(loader, 0):\n",
        "            # send data to GPU\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "        \n",
        "            outputs = model(images)\n",
        "            loss = cross_entropy(outputs, labels)\n",
        "            loss_sum += loss\n",
        "                \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            if i + 1 == nbatch:\n",
        "              break\n",
        "\n",
        "    # average loss during the epoch\n",
        "    loss_average = loss_sum / len(train_loader)\n",
        "    accuracy = correct/total\n",
        "    \n",
        "    history[name + '_loss'].append(loss_average)\n",
        "    history[name + '_accuracy'].append(accuracy)\n",
        "            \n",
        "            \n",
        "epochs = 20\n",
        "history = {'train_loss': [], 'test_loss': [],\n",
        "           'train_accuracy': [], 'test_accuracy': []}\n",
        "times_train = []\n",
        "times_test = []\n",
        "\n",
        "for iepoch in range(epochs):\n",
        "    model.train()  # 訓練モード\n",
        "    time_train = 0.0\n",
        "    for i, (images, labels) in enumerate(train_loader, 0): \n",
        "        ts = time.time()\n",
        "        \n",
        "        # send data to GPU\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "            \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(images)\n",
        "        loss = cross_entropy(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        te = time.time()\n",
        "        time_train += (te - ts)\n",
        "    \n",
        "    times_train.append(time_train)\n",
        "    \n",
        "    # Measure test accuracy for each epoch\n",
        "    ts = time.time()\n",
        "    \n",
        "    model.eval()  # evaluation モード; dropout しないなど\n",
        "    \n",
        "    measure_scores('train', train_loader, history)    \n",
        "    measure_scores('test', test_loader, history)\n",
        "    \n",
        "    \n",
        "    te = time.time()\n",
        "    times_test.append(te - ts)\n",
        "    \n",
        "    print('Epoch %d: loss %.4e %.4e, Test accuracy %.6f' % (iepoch + 1,\n",
        "          history['train_loss'][-1],\n",
        "          history['test_loss'][-1],\n",
        "          history['test_accuracy'][-1]))\n",
        "\n",
        "    \n",
        "print('Finished Training')\n",
        "print('Training %.2f ± %.2f sec per epoch' % (np.mean(times_train), np.std(times_train)))\n",
        "print('Test evaluation %.4f ± %.4f sec per epoch' % (np.mean(times_test), np.std(times_test)))\n",
        "print('Total %.2f sec' % (np.sum(times_test) + np.sum(times_test)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: loss 1.0304e-02 8.3961e-03, Test accuracy 0.983200\n",
            "Epoch 2: loss 5.5120e-03 5.3586e-03, Test accuracy 0.989200\n",
            "Epoch 3: loss 5.5392e-03 4.4336e-03, Test accuracy 0.991200\n",
            "Epoch 4: loss 3.4171e-03 4.2596e-03, Test accuracy 0.992500\n",
            "Epoch 5: loss 2.9798e-03 4.2762e-03, Test accuracy 0.991900\n",
            "Epoch 6: loss 2.3169e-03 2.8138e-03, Test accuracy 0.994800\n",
            "Epoch 7: loss 2.7404e-03 3.7591e-03, Test accuracy 0.993700\n",
            "Epoch 8: loss 2.6596e-03 3.3486e-03, Test accuracy 0.993700\n",
            "Epoch 9: loss 2.0004e-03 3.7963e-03, Test accuracy 0.993900\n",
            "Epoch 10: loss 1.8190e-03 3.2798e-03, Test accuracy 0.994500\n",
            "Epoch 11: loss 4.8030e-03 6.4935e-03, Test accuracy 0.989300\n",
            "Epoch 12: loss 2.8197e-03 4.9198e-03, Test accuracy 0.991800\n",
            "Epoch 13: loss 1.5670e-03 2.9438e-03, Test accuracy 0.995400\n",
            "Epoch 14: loss 1.8783e-03 3.6530e-03, Test accuracy 0.993600\n",
            "Epoch 15: loss 1.6968e-03 3.6187e-03, Test accuracy 0.995200\n",
            "Epoch 16: loss 8.4926e-04 3.0151e-03, Test accuracy 0.995200\n",
            "Epoch 17: loss 1.3241e-03 2.9245e-03, Test accuracy 0.994700\n",
            "Epoch 18: loss 7.2281e-04 3.8416e-03, Test accuracy 0.994700\n",
            "Epoch 19: loss 1.8084e-03 3.0019e-03, Test accuracy 0.994700\n",
            "Epoch 20: loss 1.0171e-03 3.2435e-03, Test accuracy 0.995000\n",
            "Finished Training\n",
            "Training 3.98 ± 0.06 sec per epoch\n",
            "Test evaluation 1.7637 ± 0.0108 sec per epoch\n",
            "Total 70.55 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQRq83d59E4T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "701250a0-5aa1-4d78-8bcc-0ce74ff54fd0"
      },
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.plot(history['train_loss'], label='train')\n",
        "plt.plot(history['test_loss'], label='test')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('1 - Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.plot(1 - np.array(history['train_accuracy']))\n",
        "plt.plot(1 - np.array(history['test_accuracy']))\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzOtd3oAAAHG",
        "colab_type": "text"
      },
      "source": [
        "conv を追加して深くした分、精度が良くなった、0.995. Residual block によって学習が早くなったかどうかは resdual 無しで同じ深さの `PlainNet` と比べるべきだけど、まあ動いたのでいいや."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIYJY7XM-Hfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}